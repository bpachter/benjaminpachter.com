---
layout: page
title: Skillset
permalink: /skillset/
---

## Profile:

- **Data Analytics & Visualization**:
    - I have advanced experience in **Excel Modeling**, **Power Query**, and **Power BI** for ETL data flows, primarily for creating sophisticated financial models and interactive dashboards that assist in quick and clear strategic decision-making. With proficiency in **SQL**, **DAX**, and **M scripting**, I can move and transform data effectively in a clean and centralized manner that provides maximum transparency and data refresh speed.
    - I am also highly capable within, **Tableau**, **SAS**, **Dynamics**, and **Apache** technologies such as **Spark**, **Airflow**, **Kafka**, **Storm**, **Hadoop**, **Cassandra**, **NiFi**, and **Hive** for big data processing, real-time data streaming, and distributed computing.
    - Additionally, I have operated within many cloud platforms such as **Salesforce**, **Google BigQuery**, **Amazon Redshit**, and **Azure Synapse**. 

- **Programming**:
    - I love to code! I find researching new fintech concepts extraordinarily entertaining; I spend lots of time on public academic websites such as Quant Stack Exchange, SSRN, IMF, and Coursera to stay on the frontlines of newly developed ideas and technologies. I have extensive experience pushing complex data combinations into the above visualization tools to tell interesting stories.
    - My favorite and most commonly utilized technologies are **Python**, **R**, **C++**, and **JavaScript**, but I have aggregated my total code/scripting experience below:

        - Python
        - R
        - C++
        - C#
        - JavaScript
        - Java
        - Salesforce Apex
        - SQL
        - Go
        - Pine
        - VBA
        - Ruby
        - PHP
        - Swift
        - Go
        - Scala
        - MATLAB
        - SAS
        - HTML
        - CSS
        - XML
        - Bash
        - Rust
        - PowerShell
    

    - And here are some of my favorite **Python libraries**:
        
        - Pandas
        - NumPy
        - SciPy
        - ib_insync
        - PySpark
        - PyArrow
        - PyKafka
        - PyHive
        - Airflow
        - Cassandra
        - Dask
        - fredapi
        - Matplotlib
        - Seaborn
        - Plotly
        - Bokeh
        - Scikit-learn
        - XGBoost
        - TensorFlow
        - PyTorch
        - Keras
        - Django
        - Flask
        - Geopandas
        - tqdm
        - statsmodels
        - FastAPI
        - SQLAlchemy
     

## Financial Modeling, Data Transformation, and Dashboard Development
I develop comprehensive financial and logistical models using **Python**, **SQL**, and **Power Query** to extract, transform, and load versatile data structures to tell compelling stories. The neutrality of raw data has always fascinated me, and when harnessed and channeled correctly, unbiased numbers can be translated into unbiased results that drive clear and confident decision-making.

Initializing business and economic narratives through data transformations and coding has become my hobby these days; I am personally motivated to consistently increase my tech capabilities through my own trading and investing decision optimization. Plus, it is clear that the future is filled with robots; leveraging code is the single most important tool we have available to drive into this reality!

```The robot revolution has already arrived - we just keep them in data centers and servers. - Naval Ravikant```

I've mastered traditional reporting and interactive modeling through **Excel** and **Power BI**, though I have been involved in many other technologies. Automation is the name of the game these days, and I don't spend as much time on the front-end of Excel as I used to. I'd rather transform the data in cloud servers and code the steps in a more efficient and centralized **ETL** structure before the data even gets to Excel. However, I still love to work in Excel models whenever necessary!


# Models:
In past experiences, I have developed and supported:

- **Underwriting models** for sizing up multifamily investment properties and other CRE asset types,
- **Portfolio models** for property, bond, and equity holdings evaluations,
- **Monte Carlo models** for predicting interest rate risk for securitized portfolios, carry trades, short-volatility trades, etc.,
- **Black-Scholes pricing models** for determining the fair value of options portfolios and optimizing risk management,
- and **Logistics models** that transform raw data into identifiable patterns that promote decision-making.

# Algorithms:
In my previous roles, including my time at NYMT, Deloitte, and BMW, I have designed and implemented a variety of algorithms to tackle complex problems in finance, data analysis, and optimization. Some of the standard algorithms I have worked on include:

- **Regression, Classification, and Clustering** algorithms for asset selection, credit scoring, diligence profiling, logistics pattern identification, customer segmentation, and CRE asset KPI prediction (rent prices, occupancies, cap rates, etc):
  - Everyday libraries: **Pandas**, **NumPy**, **SciPy**, **scikit-learn** for linear/logistic regression, support vector machines, and clustering algorithms, **XGBoost** and **LightGBM** for gradient boosting, and **TensorFlow**/**PyTorch** for complex neural network models and large-scale data clustering, and **Keras** for deep learning models.
    - Additional languages and libraries: **R** (**caret**, **randomForest**), **JavaScript** (**D3.js** for data visualization), **SQL** for database querying, **Go** for high-performance computing tasks, and **PySpark** (for scalable machine learning algorithms using **Spark MLlib**).

- **Optimization** algorithms for portfolio optimization and resource allocation:
  - **SciPy** for mathematical optimization, **cvxpy** for convex optimization problems, **PyPortfolioOpt** for asset portfolio optimization, **NumPy** and **Pandas** for data manipulation and numerical operations, and **PuLP** for linear programming. For larger-scale problems, I use **TensorFlow** and **PyTorch** for heavier optimization tasks with big data architecture.
    - Additional languages and libraries: **MATLAB** for high-level mathematical computations, **PySpark** (**Spark MLlib** for scalable optimization algorithms), **R** (**ROI**, **quadprog**), and **Java** (**OptaPlanner** for planning and scheduling).

- **Time series analysis** for economic, financial, sales, and transportation forecasting:
  - **Pandas** and **statsmodels** for ARIMA models, and **TensorFlow**/**Keras** for recurrent neural networks (RNNs) and long short-term memory networks (LSTMs).
    - Additional languages and libraries: **prophet** for forecasting, **R** (**forecast**, **tseries**), **PySpark** (using **Spark MLlib** for large-scale time series analysis), and **Apache Kafka** for real-time data streaming into time series analysis pipelines.

- **Ensemble methods** for improved prediction accuracy and robustness:
  - **scikit-learn** for random forests and bagging, **XGBoost**/**LightGBM** for gradient boosting, and **CatBoost** for categorical data handling.
    - Additional languages and libraries: **H2O.ai** for scalable ensemble methods, **R** (**randomForest**, **gbm**).

- **Dimensionality reduction** for enhancing model training efficiency and visualization clarity through feature scaling, reducing noise and redundancy:
  - **scikit-learn** for PCA and t-SNE, and **UMAP** for advanced dimensionality reduction techniques.
    - Additional languages and libraries: **R** (**Rtsne**, **PCAtools**), **MATLAB** (for built-in dimensionality reduction functions), and **PySpark** (using **Spark MLlib** for scalable PCA).




Outside of my professional career,  I am most interested in backtesting complex options trading strategies and automating these through brokerage APIs, as well as building my own applications. My favorite is retail brokerage automation IBKR, as it is easy to set up a paper trading account that can be directly connected to my TradingView Pine scripts for easy and transparent backtesting.

## Database and Cloud Server Management
In previous roles, I have managed database and cloud infrastructure, utilizing the following technologies:
- **SQL Server Management Studio** for testing and deploying new stored procedures and tables,
- **Salesforce Development tools** (SOQL, Apex, and Flow Automations) to ensure seamless business process optimization in CRM sites,
- **Azure**, **Google Cloud**, and **AWS** for implementing robust cloud solutions for scalable and secure database storage,
- **Apache Kafka** for managing rapid real-time data streams and **Apache HBase** for real-time read/write access to large datasets.

## Machine Learning and Data Science
This is where I find myself most of the time these days, as the implications for mastering such technologies are beyond profound. My expertise in this field spans several key areas, including predictive modeling, data manipulation, statistical analysis, and data visualization, which are all integral to drawing actionable insights from complex datasets.

I have developed and implemented a variety of predictive models using **TensorFlow**, **PyTorch**, and **Keras**. These frameworks have enabled me to build deep learning models for tasks such as time series forecasting, image recognition, and natural language processing. For instance, I have used **TensorFlow** to construct neural networks that predict financial market movements and **PyTorch** to create convolutional neural networks (CNNs) for image classification problems.

Recently, I decided to make my ML experience concrete and more robust with the online certifications provided by Deeplearning.AI and Stanford University. These courses provided solid foundations in concepts that I had already been mostly familiar with since my days at BMW Manufacturing. Some of my favorite algorithms are tree ensembles, logistic regression, feature scaling, gradient boosting, and - of course - artificial neural networks!

Most of the time, I am using the simple-to-use **Scikit-learn**, where building and evaluating ML models such as regression, decision trees, and support vector machines (SVMs) is easy and transparent. In the past, I have applied these models to multifamily rent prediction and cash flow performance models, as well as client credit scoring, customer segmentation, and portfolio risk assessment. I have applied these concepts with Yardi Matrix, Equifax, Bloomberg, and various e-commerce data structures.

My approach to machine learning and quantitative data science utilizes a combination of these technical skills and a strategic understanding of business needs. This ensures that the solutions I develop are technically sound and crystal clear in transparency, ensuring client needs are not just met but exceeded. Whether the problem is optimizing investment strategies, enabling proactive risk management, or uncovering new micro-investment opportunities, I am committed to leveraging the most advanced data science techniques available (that my 4090 Nvidia processor can manage, that is!) to drive impactful business decision making.

## Web Development and Automation
I have contributed to various web development projects utilizing frameworks such as **Django**, **Flask**, and **FastAPI**, where I worked on teams focused on integrating complex data workflows while ensuring secure data architecture transitions. My proficiency in **JavaScript** also proved invaluable here, complemented by familiarity with **HTML**/**CSS**/**HTTP** concepts.

At NYMT, I frequently operated within **Salesforce** as an end-to-end developer to support a highly customized multifamily syndication business environment. This involved enabling deal leads through the creation of dynamic and user-friendly interfaces where the entire business operated. I combined **Power BI**, **Python**, **R**, and **Salesforce Apex** (similar to JavaScript) on a daily basis to create immersive and highly customizable web dashboards for all stakeholders. I also supported in developing **Salesforce Flow Automations** for supporting granular activities where highly specialized automated processes were necessary.

Additionally, I have utilized **Go** and **Scala** for their high performance and scalability. Automation scripts written in **Bash** and **PowerShell** have streamlined repetitive tasks, and I have engaged in multicore processing projects to maximize data-churning efficiency for clients. My experience extends to **Swift** for mobile iOS development and **C#** and **Rust** for more niche development projects in the past.

I have additional exposure to a brought range of **Apache** technologies for real-time data streaming, such as **Hadoop** for large-scale data processing and storage and **Spark** for rapid distributed data processing for transportation and logistics systems.

## Investment Deal Making and Portfolio Management
As a REIT, NYMT operated simiarly to an investment bank, and provided agency-lending and preferred equity/mezzanine debt to multifamily operators. I directly supported this business through the administrative/developer concepts above, in addition to modeling and underwritten multifamily lending deals that rely on **Excel**, **Power Query**, **VBA**, **Python**, and **SQL**. It was important to understand complex credit concepts necessary for getting the numbers to line up to investment standards, and the nuances of investment banking/commercial real estate lending were things that I learned over time. A robust understanding of the capital stack structure was required for making business data decisions, and even though it was not my direct role, over time I learned to analyze specific lending deals where specialized knowledge in underwriting CRE assets for preferred equity, mezzanine, JV, and senior lending was crucial for success.

## Closing Thoughts
Thank you for taking the time to learn more about my professional journey and the skills I've developed along the way!  I'm passionate about implementing my diverse skillset in value-add projects across all sorts of fields. Though I still have much to learn, I fully recognize my own weaknesses and gaps within my own skillset that I am determined to fill in the future. It is my purpose in life to assist others and contribute to the most intelligent teams working on the newest tech capabilities available.
If you have any questions or would like to discuss potential collaborations, please don't hesitate to reach out. Let's connect and see how we can work together to achieve great things!

Cheers,  
Benjamin Pachter